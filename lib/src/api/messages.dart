part of kafka;

/// Kafka Message Attributes. Only [KafkaCompression] is supported by the
/// server at the moment.
class MessageAttributes {
  KafkaCompression compression;
  MessageAttributes([this.compression = KafkaCompression.none]);

  MessageAttributes.readFrom(KafkaBytesReader reader) {
    var attributes = reader.readInt8(); // TODO do bit manipulation magic.
    this.compression = KafkaCompression.none;
  }

  int toInt() {
    return 0;
  }
}

/// Kafka Message type as defined in the protocol specification.
class Message {
  int magicByte;
  MessageAttributes attributes;
  List<int> key;
  List<int> value;

  /// Creates new Message.
  ///
  /// The [value] can be either [String] or [List<int>] type.
  Message(dynamic value, [MessageAttributes attributes, List<int> key]) {
    this.magicByte = 0;
    this.attributes =
        (attributes == null) ? new MessageAttributes() : attributes;
    this.key = key;
    if (value is String) {
      this.value = UTF8.encode(value);
    } else if (value is List<int>) {
      this.value = value;
    } else {
      throw new StateError('Message value must be either String or List<int>');
    }
  }

  /// Creates new instance of Message from the received data.
  Message.readFrom(KafkaBytesReader reader) {
    var crc = reader.readInt32(); // TODO validate CRC
    this.magicByte = reader.readInt8();
    this.attributes = new MessageAttributes.readFrom(reader);
    this.key = reader.readBytes();
    this.value = reader.readBytes();
  }

  /// Converts Message to byte array.
  List<int> toBytes() {
    var builder = new KafkaBytesBuilder();
    builder.addInt8(magicByte);
    builder.addInt8(attributes.toInt());
    builder.addBytes(key);
    builder.addBytes(value);

    var data = builder.takeBytes();
    int crc = CRC32.compute(data);
    builder.addInt32(crc);
    builder.addRaw(data);

    return builder.toBytes();
  }
}

/// Kafka MessageSet type as defined in the protocol specification.
class MessageSet {
  /// Collection of messages. Keys in the map are message offsets.
  Map<int, Message> messages = new Map();

  /// Number of messages in this message set.
  int get length => messages.length;

  /// Creates new empty message set.
  MessageSet();

  /// Creates new MessageSet from provided data.
  MessageSet.readFrom(KafkaBytesReader reader) {
    try {
      int offset = reader.readInt64();
      int messageSize = reader.readInt32();
      var message = new Message.readFrom(reader);
      this.messages[offset] = message;
    } on RangeError {
      // no-op. According to protocol spec server is allowed to return partial
      // messages, so we just ignore it here.
    }
  }

  /// Adds [Message] to this message set.
  ///
  /// Offset for this new message will be autogenerated.
  void addMessage(Message message) {
    var offset = messages.length;
    messages[offset] = message;
  }

  /// Converts this MessageSet into sequence of bytes conforming to Kafka
  /// protocol spec.
  List<int> toBytes() {
    var builder = new KafkaBytesBuilder();
    messages.forEach((offset, message) {
      var messageData = message.toBytes();
      builder.addInt64(offset);
      builder.addInt32(messageData.length);
      builder.addRaw(messageData);
    });

    return builder.toBytes();
  }
}
